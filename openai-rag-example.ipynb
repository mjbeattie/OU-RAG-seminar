{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f29f3bf7-7e17-4c89-8f45-acb83399fd77",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# openai-rag-example\n",
    "### September 27, 2023\n",
    "\n",
    "This script uses langchain and openai to build a QA application.  It reads PDFs and stores them into a searchable vector store database.  The vector store is an Azure Cognitive Search instance.  It uses the vector store as a retriever and passes information to the LLM, which in this case is a call to the Azure OpenAI API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d3ff2852-d48b-4a50-b913-524c39ab867a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install azure-search-documents==11.4.0b8 azure-identity pypdf langchain==0.0.302 pdfplumber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize\n",
    "Load the libraries and setup your API information, including keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores.azuresearch import AzureSearch\n",
    "from langchain.retrievers import AzureCognitiveSearchRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup access to your Azure OpenAI resource using Azure keyvault stored secrets\n",
    "SECRET_SCOPE = \"<insert your Azure keyvault name here>\"\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2023-05-15\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://openai-gci-eda-ds-dev-01.openai.azure.com/\"\n",
    "OPENAI_KEY_VALUE = dbutils.secrets.get(scope = SECRET_SCOPE, key = \"<insert the name of your openai key here>\")\n",
    "OPENAI_API_ENDPOINT = \"<insert the name of your openai key here>\"\n",
    "OPENAI_LLM = \"<insert the name of your azure openai deployment here>\"\n",
    "OPENAI_EMBEDDER: str = \"<insert the name of your OpenAI embedder here>\"\n",
    "\n",
    "# Define your Cognitive Search endpoint for the vector store\n",
    "COGSRCH_ENDPOINT = \"<insert the name of your Cognitive Search endpoint here>\"\n",
    "COGSRCH_INDEX: str = \"<insert the name of the index in Cognitive Search you will generate here>\"\n",
    "COGSRCH_KEY_VALUE: str = \"<insert the name of the Cognitive Search key here>\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cbe73194-03dd-420a-908f-58587a526bb8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Load the PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de2e6fbd-563c-46d0-95c0-82b19196ed0f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "raw_folder = \"<directory to PDFs here>\"\"\n",
    "path_folder = \"<directory for vector store here>\"\n",
    "\n",
    "# Use langchain to load PDFs\n",
    "loader = PyPDFDirectoryLoader(\"<directory to PDFs here>\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d333dcc3-8150-4d32-8703-4c05652a11d7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Split the PDFs into smaller chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2018069f-f680-4ccd-8165-516700930a0e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# Define text splitter for langchain\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "\n",
    "pages = loader.load_and_split(text_splitter=text_splitter)\n",
    "print(f\"Loaded {len(pages)} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "902dbd49-9d12-46f5-ba27-d801a1d7f1f9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Encode the chunks and store them in an indexed vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "67d09447-e03c-488a-9575-12bce747c723",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Call the Azure OpenAI embedder and affiliate it to a Cognitive Search vector store\n",
    "embeddings: OpenAIEmbeddings = OpenAIEmbeddings(openai_api_key=OPENAI_KEY_VALUE, deployment=OPENAI_EMBEDDER)\n",
    "index_name: str = \"langchain-hackathon\"\n",
    "vector_store: AzureSearch = AzureSearch(\n",
    "    azure_search_endpoint=COGSRCH_ENDPOINT,\n",
    "    azure_search_key=COGSRCH_KEY_VALUE,\n",
    "    index_name=COGSRCH_INDEX,\n",
    "    embedding_function=embeddings.embed_query,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b6dd870-73a4-41f4-8e16-ac73f89044c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Using langchain, encode the PDFs and add them to the vector store\n",
    "vector_store.add_documents(documents=pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "74512d24-fcbc-4f98-8001-afb01e460741",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Perform a sample similarity search\n",
    "docs = vector_store.similarity_search(\n",
    "    query=\"How many vacation days do I get?\",\n",
    "    k=1,\n",
    "    search_type=\"similarity\",\n",
    ")\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put it all together into a QA chain\n",
    "Langchain combines the vector store retriever and the LLM into one chain that will answer a query with an informed response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b86b4fbc-eccf-41ab-8e1e-3344fde89b66",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Use langchain to combine the retriever and a call to OpenAI as an LLM to build the application\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "import langchain\n",
    "langchain.debug = True   # Set this to False once you see how it works\n",
    "\n",
    "llm = AzureChatOpenAI(deployment_name=OPENAI_LLM, temperature=0, openai_api_key=OPENAI_KEY_VALUE)\n",
    "qa_chain = RetrievalQA.from_chain_type(llm,retriever=vector_store.as_retriever(k=2))\n",
    "qa_chain({\"query\": \"How many vacation days do I get?\"})"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "openai-rag-example",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
